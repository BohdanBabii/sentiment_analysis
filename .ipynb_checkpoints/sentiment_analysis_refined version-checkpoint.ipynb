{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f61999",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Project\n",
    "\n",
    "## Introduction and Problem Statement\n",
    "Sentiment analysis is a key area in machine learning that focuses on analyzing emotions expressed in text. It has significant applications in determining public opinion, customer feedback, and social media analysis\n",
    "### Submission\n",
    "- Deadline of submission:\n",
    "19.08.2024 23:59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96db9c",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "- `data.csv`: Contains tweets with labels for training.\n",
    "- `data_validation.csv`: Used to evaluate the model with unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cec3f",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Find a way to load the dataset and transform the features `X` (Tweets) and the labels `Y` (positive/negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43008e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load data, transform into numerical features + labels\n",
    "df = pd.read_csv('data.csv', names=['labels', 'tweets'], header=None, skiprows=1)\n",
    "# Select the first 10,000 data points\n",
    "df = df.head(100000)\n",
    "\n",
    "# Extract features and labels\n",
    "X = df['tweets']\n",
    "y = df['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1623188",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Write a function to clean the tweets the data from special symbols, several and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9977ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)  # Remove URLs\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)  # Remove mentions\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)  # Remove hashtags\n",
    "    tweet = re.sub(r'\\d+', '', tweet)  # Remove numbers\n",
    "    tweet = re.sub(r'\\W+', ' ', tweet)  # Remove special characters\n",
    "    tweet = tweet.lower().strip()  # Convert to lowercase and strip whitespaces\n",
    "    return tweet\n",
    "\n",
    "# Apply the cleaning function to each tweet\n",
    "X = X.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc1e2e",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Find a way to transform the features `X` (tweets) and the labels `Y` (positive/negative) into numerical representations.\n",
    "\n",
    "For transforming tweets into features, check out the bag of words representation from [scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55153577",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "x_sparse = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "print(x_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761abe4",
   "metadata": {},
   "source": [
    "## Prior $p(S)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89f600",
   "metadata": {},
   "source": [
    "The prior distribution $p(S)$ is independent of the message $W$. We will use the maximum likelihood (ML) estimate for a categorical distribution, which is the relative frequency of the categories among the dataset.\n",
    "\\begin{align}\n",
    "p(S = \\text{positive})_{ML} &= \\cfrac{\\text{\\# tweets that are positive}}{\\text{\\# tweets}}\\\\\n",
    "p(S = \\text{negative})_{ML} &= 1 - p(S = \\text{negative})\n",
    "\\end{align}\n",
    "\n",
    "### Task 4\n",
    "\n",
    "Estimate $p(S)$. Display the estimated distribution in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: estimate p(S), display in bar chart\n",
    "p_positve = np.mean(y)\n",
    "p_negative = 1 - p_positve\n",
    "\n",
    "\n",
    "# Creating the plot\n",
    "labels = ['Negative', 'Positive']\n",
    "values = [p_negative, p_positve]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(labels, values, color=['skyblue', 'salmon'])\n",
    "\n",
    "# Adding value labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), ha='center', va='bottom')\n",
    "\n",
    "# Adding titles and labels\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Probability of Ham and Spam')\n",
    "plt.ylim(0, 1)  # Set y-axis limits to show probabilities clearly from 0 to 1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37442808",
   "metadata": {},
   "source": [
    "## Likelihood p(W|S)\n",
    "\n",
    "The likelihood distribution models how likely a tweets is, given we know its either positive or negative.\n",
    "\n",
    "\\text{tweet}]$ we would expect something like \n",
    "\\begin{align}\n",
    "p(W|S=\\text{positive}) &= \\text{low}\\\\\n",
    "p(W|S=\\text{negative}) &= \\text{medium}\\\\\n",
    "\\end{align}\n",
    "\n",
    "However to estimate $p(W|S)$ we would need a dataset with the exact same $W$ appearing in both contexts: positive and negative. Since this is not the case for our dataset, this is the part where we make a naive assumption:\n",
    "\\begin{align}\n",
    "p(W|S) = \\prod_{w\\in W}p(w|S)\n",
    "\\end{align}\n",
    "That is, we consider each word in the tweet independend of the others. This simplification enables us to estimate the likelihood, since single words to in fact appear in both contexts.\n",
    "\n",
    "For a single word $w$, we can again estimate the probability as relative frequency \n",
    "\\begin{align}\n",
    "p(w|S = \\text{positive})_{ML} &= \\cfrac{\\text{\\# word $w$ is labeled posotive}}{\\text{\\# any word is labeled positive}}\\\\\n",
    "p(w|S = \\text{negative})_{ML} &= \\cfrac{\\text{\\# word $w$ is labeled negative}}{\\text{\\# any word is labeled negative}}\\\\\n",
    "\\end{align}\n",
    "\n",
    "Since we cannot expect every word to have appeared in a positive and negative tweet, we will smooth our dataset with a [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) of $\\varepsilon = 0.001$. \n",
    "\n",
    "This is done by adding $\\varepsilon$ to the count of every word in every SMS.\n",
    "\n",
    "As an example the count vector for a SMS over a vocabulary of 5 words is transformed from\n",
    "\\begin{align}\n",
    "[1, 2, 0, 0, 1]\n",
    "\\end{align}\n",
    "into\n",
    "\\begin{align}\n",
    "[1.001, 2.001, 0.001, 0.001, 1.001]\\,.\n",
    "\\end{align}\n",
    "\n",
    "This way we do not have zero probabilities in the product for calculating $p(W|S)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: apply Laplace smoothing\n",
    "x_smooth = x_sparse + 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79988173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "from typing import Self\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier():\n",
    "    def __init__(self, laplace_smoothing_constant: float = 0.0001):\n",
    "        \"\"\"Class for binary naive Bayes.\"\"\"\n",
    "\n",
    "        self.laplace_regularization_constant = laplace_smoothing_constant\n",
    "        # n_labels x n_words\n",
    "        self.log_p_word_given_label: npt.NDArray[np.float64] = None\n",
    "        # n_labels\n",
    "        self.log_p_label: npt.NDArray[np.float64] = None\n",
    "\n",
    "    def fit(self, x: npt.NDArray[np.float64], y: npt.NDArray[np.bool_]) -> Self:\n",
    "        \"\"\"Given a dataset of count vectors, calculates probabilities needed for prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : npt.NDArray[np.float64]\n",
    "            Word count matrix (n_sms x n_words).\n",
    "        y : npt.NDArray[np.bool_]\n",
    "            Label matrix (n_sms).\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: implement\n",
    "        self.log_p_label= [np.log(np.sum(y)/ len(y)), np.log(1-np.sum(y)/ len(y))]\n",
    "        x_smooth=x+self.laplace_regularization_constant\n",
    "        spam_words= x_smooth[y==1].sum(axis=0)\n",
    "        ham_words= x_smooth[y==0].sum(axis=0)\n",
    "        self.log_p_word_given_label= np.array([[np.log(spam_words[i]/np.sum(spam_words)) for i in range(x.shape[1])], \n",
    "                                      [np.log(ham_words[i]/np.sum(ham_words)) for i in range(x.shape[1])]])\n",
    "        return self\n",
    "\n",
    "    def predict(self, x: npt.NDArray[np.float64]) -> npt.NDArray[np.bool_]:\n",
    "        \"\"\"Given a dataset of count vectors, predicts labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : npt.NDArray[np.float64]\n",
    "            Word count matrix (n_sms x n_words).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        npt.NDArray[np.bool_]\n",
    "            Vector of predictions for labels (0 = ham, 1 = spam).\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement\n",
    "        spam=[np.sum(self.log_p_word_given_label[0,x[i]!=0])+self.log_p_label[0] for i in range(x.shape[0])]\n",
    "        ham= [np.sum(self.log_p_word_given_label[1,x[i]!=0])+self.log_p_label[1] for i in range(x.shape[0])]\n",
    "        return [spam[i]>=ham[i] for i in range(len(spam))]\n",
    "        \n",
    "\n",
    "    def accuracy(self, x: npt.NDArray[np.float64], y: npt.NDArray[np.bool_]) -> float:\n",
    "        \"\"\"Calculates accuracy for given dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : npt.NDArray[np.float64]\n",
    "            Word count matrix (n_sms x n_words).\n",
    "        y : npt.NDArray[np.bool_]\n",
    "            Vector of true labels (0 = ham, 1 = spam).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Percentage of correctly classified x.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement\n",
    "        return np.sum(np.where(self.predict(x)==y, 1, 0))/len(y)\n",
    "\n",
    "\n",
    "# assertions\n",
    "classifier = NaiveBayesClassifier(laplace_smoothing_constant=0.0001).fit(x_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd37663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: provide train + testsplit\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_sparse, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, y_true, y_pred, pos_label=1):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=pos_label)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=pos_label)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with Naive Bayes approach\n",
    "model = NaiveBayesClassifier(laplace_smoothing_constant=0.0002)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Naive Bayes')\n",
    "evaluate_model('Naive Bayes', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with Logistic Regression approach\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Logistic Regression')\n",
    "evaluate_model('Logistic Regression', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d35e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with Support Vector Machine approach\n",
    "model = SVC(kernel='linear', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Support Vector Machine')\n",
    "evaluate_model('SVM', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(results):\n",
    "    models = [result['model'] for result in results]\n",
    "    accuracies = [result['accuracy'] for result in results]\n",
    "    recalls = [result['recall'] for result in results]\n",
    "    precisions = [result['precision'] for result in results]\n",
    "    f1_scores = [result['f1_score'] for result in results]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    axs[0, 0].bar(models, accuracies, color='skyblue')\n",
    "    axs[0, 0].set_title('Accuracy')\n",
    "    axs[0, 0].set_ylim([0, 1])\n",
    "    \n",
    "    axs[0, 1].bar(models, recalls, color='lightgreen')\n",
    "    axs[0, 1].set_title('Recall')\n",
    "    axs[0, 1].set_ylim([0, 1])\n",
    "    \n",
    "    axs[1, 0].bar(models, precisions, color='salmon')\n",
    "    axs[1, 0].set_title('Precision')\n",
    "    axs[1, 0].set_ylim([0, 1])\n",
    "    \n",
    "    axs[1, 1].bar(models, f1_scores, color='lightcoral')\n",
    "    axs[1, 1].set_title('F1 Score')\n",
    "    axs[1, 1].set_ylim([0, 1])\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set_xticks(range(len(models)))\n",
    "        ax.set_xticklabels(models)\n",
    "        ax.set_xlabel('Model')\n",
    "        ax.set_ylabel('Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
